{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HiranmaiKaredla/NLP/blob/main/pos_tagging_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Abbreviation\tMeaning\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tThis NLTK POS Tag is an adjective (large)\n",
        "JJR\tadjective, comparative (larger)\n",
        "JJS\tadjective, superlative (largest)\n",
        "LS\tlist market\n",
        "MD\tmodal (could, will)\n",
        "NN\tnoun, singular (cat, tree)\n",
        "NNS\tnoun plural (desks)\n",
        "NNP\tproper noun, singular (sarah)\n",
        "NNPS\tproper noun, plural (indians or americans)\n",
        "PDT\tpredeterminer (all, both, half)\n",
        "POS\tpossessive ending (parent\\ ‘s)\n",
        "PRP\tpersonal pronoun (hers, herself, him, himself)\n",
        "PRP$\tpossessive pronoun (her, his, mine, my, our )\n",
        "RB\tadverb (occasionally, swiftly)\n",
        "RBR\tadverb, comparative (greater)\n",
        "RBS\tadverb, superlative (biggest)\n",
        "RP\tparticle (about)\n",
        "TO\tinfinite marker (to)\n",
        "UH\tinterjection (goodbye)\n",
        "VB\tverb (ask)\n",
        "VBG\tverb gerund (judging)\n",
        "VBD\tverb past tense (pleaded)\n",
        "VBN\tverb past participle (reunified)\n",
        "VBP\tverb, present tense not 3rd person singular(wrap)\n",
        "VBZ\tverb, present tense with 3rd person singular (bases)\n",
        "WDT\twh-determiner (that, what)\n",
        "WP\twh- pronoun (who)\n",
        "WRB\twh- adverb (how)\n",
        "'''"
      ],
      "metadata": {
        "id": "VQAgCmtKbNmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "c3d2f87f-e3cd-4609-b6af-c170554191e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAbbreviation\\tMeaning\\nCC\\tcoordinating conjunction\\nCD\\tcardinal digit\\nDT\\tdeterminer\\nEX\\texistential there\\nFW\\tforeign word\\nIN\\tpreposition/subordinating conjunction\\nJJ\\tThis NLTK POS Tag is an adjective (large)\\nJJR\\tadjective, comparative (larger)\\nJJS\\tadjective, superlative (largest)\\nLS\\tlist market\\nMD\\tmodal (could, will)\\nNN\\tnoun, singular (cat, tree)\\nNNS\\tnoun plural (desks)\\nNNP\\tproper noun, singular (sarah)\\nNNPS\\tproper noun, plural (indians or americans)\\nPDT\\tpredeterminer (all, both, half)\\nPOS\\tpossessive ending (parent\\\\ ‘s)\\nPRP\\tpersonal pronoun (hers, herself, him, himself)\\nPRP$\\tpossessive pronoun (her, his, mine, my, our )\\nRB\\tadverb (occasionally, swiftly)\\nRBR\\tadverb, comparative (greater)\\nRBS\\tadverb, superlative (biggest)\\nRP\\tparticle (about)\\nTO\\tinfinite marker (to)\\nUH\\tinterjection (goodbye)\\nVB\\tverb (ask)\\nVBG\\tverb gerund (judging)\\nVBD\\tverb past tense (pleaded)\\nVBN\\tverb past participle (reunified)\\nVBP\\tverb, present tense not 3rd person singular(wrap)\\nVBZ\\tverb, present tense with 3rd person singular (bases)\\nWDT\\twh-determiner (that, what)\\nWP\\twh- pronoun (who)\\nWRB\\twh- adverb (how)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Task 1: For the book, \"Harry Potter and the Sorcerer's Stone,\" determine:\n",
        "1. 3 most frequent POS tags\n",
        "2. 3 least frequent POS tags\n",
        "\n",
        "Task 2: For the sentence, \"Harry took a great running jump.\", determine:\n",
        "1. POS tags for each word in the sentence\n",
        "'''"
      ],
      "metadata": {
        "id": "canD1govamN8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6b4ba22c-8d8d-4661-9418-16b138175cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTask 1: For the book, \"Harry Potter and the Sorcerer\\'s Stone,\" determine:\\n1. 3 most frequent POS tags\\n2. 3 least frequent POS tags\\n\\nTask 2: For the sentence, \"Harry took a great running jump.\", determine:\\n1. POS tags for each word in the sentence\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4UJTOngo546"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download resources\n",
        "!{sys.executable} -m nltk.downloader 'punkt'\n",
        "!{sys.executable} -m nltk.downloader 'averaged_perceptron_tagger'\n",
        "!{sys.executable} -m pip install svgling"
      ],
      "metadata": {
        "id": "RxHcu_85sJ9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e067727-6d7e-4f40-ced2-03b2bb08a00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import text\n",
        "fn = 'Harrypotter.txt'\n",
        "with open(fn, 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(text[:2000])"
      ],
      "metadata": {
        "id": "vTfSFfRSpUoH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d23a02-5ff8-4055-dc06-ecb2bd4c5de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harry Potter and the Sorcerer's Stone \n",
            "\n",
            "CHAPTER ONE \n",
            "\n",
            "THE BOY WHO LIVED \n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. \n",
            "\n",
            "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. \n",
            "\n",
            "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn't think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley's sister, but they hadn't met for several years; in fact, Mrs. Dursley pretended she didn't have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn't want Dudley mixing with a child like that. \n",
            "\n",
            "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair. \n",
            "\n",
            "None of them noticed a large, tawny owl flutter past the window. \n",
            "\n",
            "At hal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sentences\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "print('')\n",
        "print('Sentence examples, original')\n",
        "for i in range(0, 5):\n",
        "  print(i, sentences[i])\n",
        "\n",
        "print('')\n",
        "print('Sentence count', len(sentences))"
      ],
      "metadata": {
        "id": "suoPxlBWrj8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f59756-c4c6-42f2-f90f-57295f55910e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence examples, original\n",
            "0 Harry Potter and the Sorcerer's Stone \n",
            "\n",
            "CHAPTER ONE \n",
            "\n",
            "THE BOY WHO LIVED \n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\n",
            "1 They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
            "2 Mr. Dursley was the director of a firm called Grunnings, which made drills.\n",
            "3 He was a big, beefy man with hardly any neck, although he did have a very large mustache.\n",
            "4 Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors.\n",
            "\n",
            "Sentence count 6394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize words\n",
        "tokens = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "print('')\n",
        "print('Tokensization examples')\n",
        "for i in range(0, 5):\n",
        "  print(i, tokens[i])\n",
        "\n",
        "print('')\n",
        "print('Sentence count', len(tokens))"
      ],
      "metadata": {
        "id": "sRWGBLs7rs7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab73f43-f824-4dbe-d176-4e9c70f74630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokensization examples\n",
            "0 ['Harry', 'Potter', 'and', 'the', 'Sorcerer', \"'s\", 'Stone', 'CHAPTER', 'ONE', 'THE', 'BOY', 'WHO', 'LIVED', 'Mr.', 'and', 'Mrs.', 'Dursley', ',', 'of', 'number', 'four', ',', 'Privet', 'Drive', ',', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', ',', 'thank', 'you', 'very', 'much', '.']\n",
            "1 ['They', 'were', 'the', 'last', 'people', 'you', \"'d\", 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', ',', 'because', 'they', 'just', 'did', \"n't\", 'hold', 'with', 'such', 'nonsense', '.']\n",
            "2 ['Mr.', 'Dursley', 'was', 'the', 'director', 'of', 'a', 'firm', 'called', 'Grunnings', ',', 'which', 'made', 'drills', '.']\n",
            "3 ['He', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.']\n",
            "4 ['Mrs.', 'Dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', ',', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', ',', 'spying', 'on', 'the', 'neighbors', '.']\n",
            "\n",
            "Sentence count 6394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate part of speech tags\n",
        "tagged = [nltk.pos_tag(sent) for sent in tokens]\n",
        "print('')\n",
        "print('Tagging examples')\n",
        "for i in range(0, 5):\n",
        "  print(i, tagged[i])\n",
        "\n",
        "print('')\n",
        "print('Sentence count', len(tagged))"
      ],
      "metadata": {
        "id": "AYbINU2ksXlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31836a73-8dd0-4adc-e0c9-2471104bb27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tagging examples\n",
            "0 [('Harry', 'NNP'), ('Potter', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('Sorcerer', 'NNP'), (\"'s\", 'POS'), ('Stone', 'NNP'), ('CHAPTER', 'NNP'), ('ONE', 'NNP'), ('THE', 'NNP'), ('BOY', 'NNP'), ('WHO', 'NNP'), ('LIVED', 'NNP'), ('Mr.', 'NNP'), ('and', 'CC'), ('Mrs.', 'NNP'), ('Dursley', 'NNP'), (',', ','), ('of', 'IN'), ('number', 'NN'), ('four', 'CD'), (',', ','), ('Privet', 'NNP'), ('Drive', 'NNP'), (',', ','), ('were', 'VBD'), ('proud', 'JJ'), ('to', 'TO'), ('say', 'VB'), ('that', 'IN'), ('they', 'PRP'), ('were', 'VBD'), ('perfectly', 'RB'), ('normal', 'JJ'), (',', ','), ('thank', 'NN'), ('you', 'PRP'), ('very', 'RB'), ('much', 'RB'), ('.', '.')]\n",
            "1 [('They', 'PRP'), ('were', 'VBD'), ('the', 'DT'), ('last', 'JJ'), ('people', 'NNS'), ('you', 'PRP'), (\"'d\", 'MD'), ('expect', 'VB'), ('to', 'TO'), ('be', 'VB'), ('involved', 'VBN'), ('in', 'IN'), ('anything', 'NN'), ('strange', 'JJ'), ('or', 'CC'), ('mysterious', 'JJ'), (',', ','), ('because', 'IN'), ('they', 'PRP'), ('just', 'RB'), ('did', 'VBD'), (\"n't\", 'RB'), ('hold', 'VB'), ('with', 'IN'), ('such', 'JJ'), ('nonsense', 'NN'), ('.', '.')]\n",
            "2 [('Mr.', 'NNP'), ('Dursley', 'NNP'), ('was', 'VBD'), ('the', 'DT'), ('director', 'NN'), ('of', 'IN'), ('a', 'DT'), ('firm', 'NN'), ('called', 'VBN'), ('Grunnings', 'NNP'), (',', ','), ('which', 'WDT'), ('made', 'VBD'), ('drills', 'NNS'), ('.', '.')]\n",
            "3 [('He', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('big', 'JJ'), (',', ','), ('beefy', 'JJ'), ('man', 'NN'), ('with', 'IN'), ('hardly', 'RB'), ('any', 'DT'), ('neck', 'NN'), (',', ','), ('although', 'IN'), ('he', 'PRP'), ('did', 'VBD'), ('have', 'VB'), ('a', 'DT'), ('very', 'RB'), ('large', 'JJ'), ('mustache', 'NN'), ('.', '.')]\n",
            "4 [('Mrs.', 'NNP'), ('Dursley', 'NNP'), ('was', 'VBD'), ('thin', 'JJ'), ('and', 'CC'), ('blonde', 'NN'), ('and', 'CC'), ('had', 'VBD'), ('nearly', 'RB'), ('twice', 'RB'), ('the', 'DT'), ('usual', 'JJ'), ('amount', 'NN'), ('of', 'IN'), ('neck', 'NN'), (',', ','), ('which', 'WDT'), ('came', 'VBD'), ('in', 'IN'), ('very', 'RB'), ('useful', 'JJ'), ('as', 'IN'), ('she', 'PRP'), ('spent', 'VBD'), ('so', 'RB'), ('much', 'JJ'), ('of', 'IN'), ('her', 'PRP$'), ('time', 'NN'), ('craning', 'NN'), ('over', 'IN'), ('garden', 'NN'), ('fences', 'NNS'), (',', ','), ('spying', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('neighbors', 'NNS'), ('.', '.')]\n",
            "\n",
            "Sentence count 6394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get frequency distribution of tags\n",
        "tags_only = [tag for sent in tagged for (word, tag) in sent]\n",
        "tag_freq = nltk.FreqDist(tags_only)\n",
        "\n",
        "print('')\n",
        "print('Tag freq')\n",
        "print(tag_freq)\n",
        "print(pd.DataFrame(tag_freq.most_common(), columns=['tag', 'count']))"
      ],
      "metadata": {
        "id": "2QQe0c4lsXsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca86be55-3740-45e7-9f6c-b038ca17b018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tag freq\n",
            "<FreqDist with 41 samples and 98782 outcomes>\n",
            "     tag  count\n",
            "0     NN   9980\n",
            "1     IN   8070\n",
            "2    PRP   7378\n",
            "3    VBD   7348\n",
            "4    NNP   7102\n",
            "5     DT   6897\n",
            "6      .   6347\n",
            "7      ,   5658\n",
            "8     RB   5561\n",
            "9     JJ   4091\n",
            "10    VB   3463\n",
            "11    ''   2660\n",
            "12   NNS   2614\n",
            "13    CC   2526\n",
            "14    ``   2307\n",
            "15   VBG   2105\n",
            "16    TO   1859\n",
            "17   VBN   1734\n",
            "18   VBP   1677\n",
            "19  PRP$   1662\n",
            "20    MD   1315\n",
            "21     :   1227\n",
            "22   VBZ    957\n",
            "23    RP    756\n",
            "24   POS    718\n",
            "25    CD    555\n",
            "26    WP    552\n",
            "27   WRB    492\n",
            "28   WDT    224\n",
            "29    EX    212\n",
            "30   JJR    168\n",
            "31    UH    154\n",
            "32   JJS    117\n",
            "33   PDT     79\n",
            "34   RBR     79\n",
            "35  NNPS     33\n",
            "36     )     33\n",
            "37     (     30\n",
            "38   RBS     21\n",
            "39    FW     18\n",
            "40   WP$      3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a specific sentence with pos tags\n",
        "text = \"Harry took a great running jump.\"\n",
        "print(text)\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "tags = nltk.pos_tag(tokens)\n",
        "print(tags)\n",
        "\n",
        "# NN - noun, singular or mass\n",
        "# DT - determiner\n",
        "# JJ - adjective\n",
        "# NP - noun phrase\n",
        "grammar = \"NP:{<DT>?<JJ>*<NN>}\"\n",
        "print(grammar)\n",
        "\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "print(cp)\n",
        "\n",
        "result = cp.parse(tags)\n",
        "print(result)\n",
        "display(result)"
      ],
      "metadata": {
        "id": "fXa28Ax9uC30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "d8621715-8b74-4294-aaae-40aef2217324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harry took a great running jump.\n",
            "['Harry', 'took', 'a', 'great', 'running', 'jump', '.']\n",
            "[('Harry', 'NNP'), ('took', 'VBD'), ('a', 'DT'), ('great', 'JJ'), ('running', 'JJ'), ('jump', 'NN'), ('.', '.')]\n",
            "NP:{<DT>?<JJ>*<NN>}\n",
            "chunk.RegexpParser with 1 stages:\n",
            "RegexpChunkParser with 1 rules:\n",
            "       <ChunkRule: '<DT>?<JJ>*<NN>'>\n",
            "(S Harry/NNP took/VBD (NP a/DT great/JJ running/JJ jump/NN) ./.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [('Harry', 'NNP'), ('took', 'VBD'), Tree('NP', [('a', 'DT'), ('great', 'JJ'), ('running', 'JJ'), ('jump', 'NN')]), ('.', '.')])"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,336.0,168.0\" width=\"336px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"16.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">Harry</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.33333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"14.2857%\" x=\"16.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">took</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.8095%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"61.9048%\" x=\"30.9524%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"15.3846%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"7.69231%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"26.9231%\" x=\"15.3846%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">great</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.8462%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"34.6154%\" x=\"42.3077%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">running</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.6154%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"23.0769%\" x=\"76.9231%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">jump</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.4615%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.9048%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"7.14286%\" x=\"92.8571%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"96.4286%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(tag_freq.most_common(), columns=['tag', 'count'])"
      ],
      "metadata": {
        "id": "D-EwF_oaSPuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tag'][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cROjg6U3ScNc",
        "outputId": "f91080b1-355f-4f8b-e772-2e0b977adcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     NN\n",
              "1     IN\n",
              "2    PRP\n",
              "Name: tag, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tag'][-3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC0oumRGSe-W",
        "outputId": "d79ad1e4-30d4-420c-97e7-86af83ebb41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38    RBS\n",
              "39     FW\n",
              "40    WP$\n",
              "Name: tag, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sn4Ee80tSnOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}